{% extends "base.html" %}
{% load static %}
{% block content %}
<!--some code taken and customized to suit my needs from https://github.com/wrongakram/html-css-hero-animation/tree/master-->
{% if user.is_authenticated %}
<section class="about" >
    <div class="container">
        <div class="row">
            <div class="about-inner">
                <div class="about-content">
                    <div class="image-inner">
                        <img src="{% static 'img/about-image.svg' %}" />
                    </div>
                    <div class="image-inner-2">
                        <img src="{% static 'img/happy-image.svg' %}" />
                    </div>
                    <h3>
                        Here to help you overcome your emotions
                    </h3>
                    <p>
                        Lolly is here for everyone to talk to about anything - anytime - anywhere.
                    </p>
                    <div class="btn-row">
                        <a href="/profile">Profile</a>
                    </div>
                </div>
                <div class="about-list">
                    <ul>
                        <li>
                            <img src="{% static 'img/goal.svg' %}"/>
                            <h5>Goal</h5>
                            <p>
                                Lolly's goal is to help people overcome their emotions
                                during the coronavirus lockdown. We know that people are
                                on lockdown and find it hard to talk to other people about
                                their feelings. Lolly is here for anyone to talk to about anything.
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/lolly_avatar.png' %}"/>
                            <h5>Lolly</h5>
                            <p>
                                Lolly is an emotion-based chatbot that communicates
                                to the user depending on the emotions detect through
                                the user's face. Depending on what facial expressions are detected,
                                Lolly will communicate to the user differently.
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/developer.svg' %}"/>
                            <h5>Developer</h5>
                            <p>
                                Lolly is developed by Latif Yahia for his final
                                year college project. The code for this project can be
                                found on GitHub <a href="https://github.com/latifyahia/EmotionAIChatbotProject">here</a>.
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/features.svg' %}"/>
                            <h5>Features</h5>
                            <p>
                                • Facial Recognition

                            </p>
                            <p>
                                • Machine Learning
                            </p>
                            <p>
                                • User Registration
                            </p>
                            <p>
                                • Personal Profile
                            </p>
                            <p>
                                • Emotional Detection Statistics
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/face-reg.svg' %}"/>
                            <h5>Facial Recognition</h5>
                            <p>
                                Lolly uses facial recognition to detect emotions displayed by the user's face.
                                Lolly uses these emotions to communicate to the user differently.
                                Lolly uses a JavaScript library for facial recognition called face-api.js
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/machine-learning.svg' %}"/>
                            <h5>Machine Learning</h5>
                            <p>
                                Lolly is created using the machine learning NLU model. An NLU model
                                is used for speech recognition. The NLU model improves over time as the
                                model recognizes syntax, context, and language patterns. Lolly is created
                                using this NLU model from the RASA open-source framework.
                            </p>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>

{% else %}
<section class="about" >
    <div  class="banner-bg"></div>
    <div class="container">
        <div class="row">
            <div class="about-inner">
                <div class="about-content">
                    <div class="image-inner">
                        <img src="{% static 'img/about-image.svg' %}" />
                    </div>
                    <div class="image-inner-2">
                        <img src="{% static 'img/happy-image.svg' %}" />
                    </div>
                    <h3>
                        Lolly is here for everyone to talk to about anything - anytime - anywhere.
                    </h3>
                    <p>
                        Lolly's goal is to help people overcome their emotions
                        during the coronavirus lockdown. We know that people are
                        on lockdown and find it hard to talk to other people about
                        their feelings. Lolly is here for anyone to talk to about anything.
                    </p>
                    <div class="btn-row">
                        <a #href="/register">Register</a>
                    </div>
                </div>
                <div class="about-list">
                    <ul>
                        <li>
                            <img src="{% static 'img/goal.svg' %}"/>
                            <h5>Goal</h5>
                            <p>
                                Lolly is an emotion-based chatbot that communicates
                                to the user depending on the emotions detect through
                                the user's face. Depending on what facial expressions are detected,
                                Lolly will communicate to the user differently.
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/lolly_avatar.png' %}"/>
                            <h5>Lolly</h5>
                            <p>
                                Lolly is developed by Latif Yahia for his final
                                year college project. The code for this project can be
                                found on GitHub <a href="https://github.com/latifyahia/EmotionAIChatbotProject">here</a>.
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/developer.svg' %}"/>
                            <h5>Developer</h5>
                            <p>
                                Lolly is developed by Latif Yahia for his final
                                year college project. The code for this project can be
                                found on GitHub <a href="https://github.com/latifyahia/EmotionAIChatbotProject">here</a>.
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/features.svg' %}"/>
                            <h5>Features</h5>
                            <p>
                                • Facial Recognition

                            </p>
                            <p>
                                • Machine Learning
                            </p>
                            <p>
                                • User Registration
                            </p>
                            <p>
                                • Personal Profile
                            </p>
                            <p>
                                • Emotional Detection Statistics
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/face-reg.svg' %}"/>
                            <h5>Facial Recognition</h5>
                            <p>
                                Lolly uses facial recognition to detect emotions displayed by the user's face.
                                Lolly uses these emotions to communicate to the user differently.
                                Lolly uses a JavaScript library for facial recognition called face-api.js
                            </p>
                        </li>
                        <li>
                            <img src="{% static 'img/machine-learning.svg' %}"/>
                            <h5>Machine Learning</h5>
                            <p>
                                Lolly is created using the machine learning NLU model. An NLU model
                                is used for speech recognition. The NLU model improves over time as the
                                model recognizes syntax, context, and language patterns. Lolly is created
                                using this NLU model from the RASA open-source framework.
                            </p>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>
{% endif %}

<script>
    const h3Content = document.querySelectorAll(".about-content h3")
    const pContent = document.querySelector(".about-content p")
    const aboutImages = document.querySelectorAll(".about-list img")
    const aboutHeader = document.querySelectorAll(".about-list h5")
    const aboutParagraph = document.querySelectorAll(".about-list p")
    const button = document.querySelector(".btn-row")
    const timeLine = gsap.timeline();
    const img1 = document.querySelector(".image-inner img")
    const img2 = document.querySelector(".image-inner-2 img")


    gsap.from(img1, {
        x:-1000,
        opacity:0,
        duration: 1.5,
        ease: "power3.out",

    })

    gsap.from(img2, {
        x:1000,
        opacity:0,
        duration: 1.5,
        ease: "power3.out",

    })

    timeLine
        .from(h3Content,{
            delay:0.8,
            y:80,
            opacity:0,
            duration:0.8,
            ease: 'power3.out',
            stagger: {
                amount:0.2
            }
        }).from([pContent, button],{
        y:-40,
        duration: 0.8,
        opacity: 0,
        ease: "power3.out",
        stagger: {
            amount:0.2
        }
    })

    gsap.from(aboutImages,{
        delay: 0.8,
        x:-100,
        skewX:2,
        opacity:0,
        duration:0.8,
        ease: 'power3.out',
        
    })
    gsap.from(aboutHeader,{
        delay:1.3,
        x:60,
        skewX:6,
        opacity:0,
        duration:0.8,
        ease: 'power3.out',
        stagger: {
            amount:0.2
        }
    })
    gsap.from(aboutParagraph,{
        delay:1.6,
        x:60,
        skewX:6,
        opacity:0,
        duration:0.8,
        ease: 'power3.out',
        stagger: {
            amount:0.2
        }
    })
</script>

{% endblock %}